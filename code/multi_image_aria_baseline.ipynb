{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91773b2a-297c-4b3d-92cc-9c232c0ef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def open_images_from_directory(directory):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    img = []\n",
    "    for file in (files):\n",
    "        # Check if the file is an image and only take the first 4 frames\n",
    "        if len(img) < 4: \n",
    "            if file.endswith('.jpg'):\n",
    "                try:\n",
    "                    image_path = os.path.join(directory, file)\n",
    "                    img.append(Image.open(image_path))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error opening image {file}: {e}\")\n",
    "        else:\n",
    "            break\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f8f1a8-c533-4438-a5af-34f4648a96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq, AutoModelForCausalLM\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffc8c5e-8581-4111-b8ac-a2936e2880e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_messages(image_array):\n",
    "    # Generate image content based on the length of image_array\n",
    "    image_contents = [{\"type\": \"image\"} for _ in image_array]\n",
    "    \n",
    "    # Add the text message to describe the images\n",
    "    \n",
    "    text_content = {\"type\": \"text\", \"text\": \"Analyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"}\n",
    "            \n",
    "    # Combine image contents and text content\n",
    "    messages = [{\"role\": \"user\", \"content\": image_contents + [text_content]}]\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837dfc3d-a8c7-4069-9ca2-c27c3bf680c8",
   "metadata": {},
   "source": [
    "**SmolVLM-Instruct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56d045-eb4d-4988-b3a2-e1e580af69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor, model and load PEFT adapter\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    _attn_implementation=\"flash_attention_2\" if DEVICE == \"cuda\" else \"eager\",\n",
    ").to(DEVICE)\n",
    "model.load_adapter(\"HuggingFaceTB/SmolVLM-Instruct-DPO\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "219e75ea-42ee-48c9-b416-2b79af977d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze\")\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze/\" + sample)\n",
    "    messages = create_input_messages(img)\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    \n",
    "    # Process inputs\n",
    "    inputs = processor(text=prompt, images=img, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(DEVICE)\n",
    "\n",
    "    # Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=500)[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'SmolVLM-Instruct(B)'] = int(float(generated_texts))\n",
    "    \n",
    "    # Delete the variables to free up memory\n",
    "    del img, messages, prompt, inputs, generated_ids, generated_texts\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(dataset_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0749c06a-7ec1-4c65-a3d7-6a75dab90a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "def create_input_messages(image_array):\n",
    "    # Generate image content based on the length of image_array\n",
    "    image_contents = [{\"type\": \"image\"} for _ in image_array]\n",
    "    \n",
    "    # Add the text message to describe the images\n",
    "    \n",
    "    text_content = {\"type\": \"text\", \"text\": \"Analyze this sequence of frames. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"}\n",
    "            \n",
    "    # Combine image contents and text content\n",
    "    messages = [{\"role\": \"user\", \"content\": image_contents + [text_content]}]\n",
    "    \n",
    "    return messages\n",
    "    # Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze\")\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze/\" + sample)\n",
    "    messages = create_input_messages(img)\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    \n",
    "    # Process inputs\n",
    "    inputs = processor(text=prompt, images=img, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(DEVICE)\n",
    "\n",
    "    # Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=500)[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'SmolVLM-Instruct(B)'] = int(float(generated_texts))\n",
    "    \n",
    "    # Delete the variables to free up memory\n",
    "    del img, messages, prompt, inputs, generated_ids, generated_texts\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(dataset_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2007a7-a05f-4d4d-a083-c788b56deb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"User: Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.<image>Assistant: 0\\nUser: Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.<image>Assistant: A person is holding a blue thermos in front of a wall with multiple monitors.\"]\n"
     ]
    }
   ],
   "source": [
    "# Tried a few shot prompt with one example but did not even output if it was a picking or placing task\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.\"},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"0\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.\"},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load images\n",
    "img_prompt = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/mcq/all_frames/Pick up jug from table_58929010438104.00\")\n",
    "img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze/Place_P0001_a68492d5_new_2\")\n",
    "\n",
    "# Combine image lists\n",
    "if not isinstance(img_prompt, list) or not isinstance(img, list):\n",
    "    raise ValueError(\"Images must be loaded as lists.\")\n",
    "img_new = img_prompt + img\n",
    "\n",
    "# Prepare the prompt\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "# Prepare inputs\n",
    "inputs = processor(text=prompt, images=img_new, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "# Output results\n",
    "print(generated_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecef077-a56a-43c8-85e8-571d3b09c7fd",
   "metadata": {},
   "source": [
    "**llava-hf/llava-onevision-qwen2-7b-ov-hf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b5521e6-8be8-4f43-8ceb-a22873042c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ac81990e145429005ebd2e7887d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration\n",
    "\n",
    "# Load the model in half-precision\n",
    "model = LlavaOnevisionForConditionalGeneration.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-onevision-qwen2-7b-ov-hf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa141cca-c879-47fa-b081-cbb72e5a1826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick up_P0001_a68492d5_new_1 is in device\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze\")\n",
    "messages = [{'role': 'user',\n",
    "  'content': [{'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'text',\n",
    "    'text': \"Analyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"}]}]\n",
    "\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze/\" + sample)\n",
    "    \n",
    "    inputs = processor(images=img, text=prompt, padding=True, return_tensors=\"pt\").to(model.device, torch.float16)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    print(sample, 'is in device') \n",
    "    #Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    \n",
    "    \n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'llava(B)'] = int(float(generated_texts))\n",
    "    df.to_csv(dataset_path, index=False)\n",
    "    # Delete the variables to free up memory\n",
    "    del img, inputs, generated_ids, generated_texts, action_class\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684d56b-7ac0-4262-b210-bcf5a816d817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze\")\n",
    "messages = [{'role': 'user',\n",
    "  'content': [{'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'image'},\n",
    "   {'type': 'text',\n",
    "    'text': \"Analyze this sequence of frames. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"}]}]\n",
    "\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze/\" + sample)\n",
    "    \n",
    "    inputs = processor(images=img, text=prompt, padding=True, return_tensors=\"pt\").to(model.device, torch.float16)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    # Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    \n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'llava(B)'] = int(float(generated_texts))\n",
    "    df.to_csv(dataset_path, index=False)\n",
    "    # Delete the variables to free up memory\n",
    "    del img, inputs, generated_ids, generated_texts, action_class\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec971200-e3a4-4ef4-b332-bda86c1fd4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trying few shot\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames\")\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.\"},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'role': 'assistant',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"0\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {'type': 'text', 'text': \"Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.\"},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'},\n",
    "            {'type': 'image'}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img_prompt = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/mcq/all_frames/Pick up jug from table_58929010438104.00\")\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames\" + sample)\n",
    "    img_new = img_prompt + img\n",
    "    \n",
    "    inputs = processor(images=img_new, text=prompt, padding=True, return_tensors=\"pt\").to(model.device, torch.float16)\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    # Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=100)[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    \n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'llava(few)'] = int(float(generated_texts))\n",
    "    df.to_csv(dataset_path, index=False)\n",
    "    # Delete the variables to free up memory\n",
    "    del img, inputs, generated_ids, generated_texts, action_class\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e858cff-bd87-42e8-b482-405fd26071ae",
   "metadata": {},
   "source": [
    "**\"microsoft/Phi-3.5-vision-instruct\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5001df64-c3cd-4703-bf08-8e9ebd5ffb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1034f935412479eb2a39543eccb9f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229ead5d46e54701983ea3ff2e68892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccea123d58374e269998d972fd90d004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3333a7abd89e461ab331080d7cd09c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7584d3ff36b7436eb3b2e9208d80f15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM \n",
    "model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  model_id, \n",
    "  device_map=\"cuda\", \n",
    "  trust_remote_code=True, \n",
    "  torch_dtype=\"auto\", \n",
    "  _attn_implementation='flash_attention_2' #'eager'   \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb12867-775d-4e7b-b056-df68e67ebe6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze\")\n",
    "\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze/\" + sample)\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "      [\n",
    "            {\"role\": \"user\", \"content\": \"<|image_1|>\\n<|image_2|>\\n<|image_3|>\\n<|image_4|>\\nAnalyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"},\n",
    "        ], \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    inputs = processor(prompt, img, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 1000, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    \n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'Phi3.5(B)'] = int(float(generated_texts))\n",
    "    \n",
    "    # Delete the variables to free up memory\n",
    "    del img, prompt, inputs, generate_ids, generated_texts\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(dataset_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73738b86-b9de-49b5-b4f5-695604993d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated text:  1\n",
      "Accuracy:  0.375\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze\")\n",
    "\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/nogaze/\" + sample)\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "      [\n",
    "            {\"role\": \"user\", \"content\": \"<|image_1|>\\n<|image_2|>\\n<|image_3|>\\n<|image_4|>\\nAnalyze this sequence of frames. Identify whether the user is performing a pick or place task. Output '0' if it is pick or '1' if it is place.\"},\n",
    "        ], \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    inputs = processor(prompt, img, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 1000, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    \n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    if action_class in generated_texts:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'Phi3.5(B)'] = int(float(generated_texts))\n",
    "    \n",
    "    # Delete the variables to free up memory\n",
    "    del img, prompt, inputs, generate_ids, generated_texts\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(dataset_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b48f62-d1f0-4f55-b073-57bd8d561800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames\")\n",
    "\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames\" + sample)\n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "      [\n",
    "            {\"role\": \"user\", \"content\": \"<|image_1|>\\n<|image_2|>\\n<|image_3|>\\n<|image_4|>\\nAnalyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task and explain.\"},\n",
    "        ], \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    inputs = processor(prompt, img, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 1000, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    print(\"generated text: \", generated_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f96e4dd6-4a23-4225-9256-02d8e0c19aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttyh/hot3d/hot3d/.pixi/envs/default/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_ids:  tensor([[    1, 32010, 29871,  ..., 29900, 32007, 32000]], device='cuda:0')\n",
      "generated text:  0\n",
      "wrong\n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Try few shot\n",
    "dataset_path = '/home/ttyh/hot3d/hot3d/dataset/mcq/gazevsnogaze.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "data = os.listdir(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze\")\n",
    "messages = [\n",
    "            {\"role\": \"user\", \"content\": \"<|image_1|>\\n<|image_2|>\\n<|image_3|>\\n<|image_4|>\\nAnalyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task and explain.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"0\"},\n",
    "            {\"role\": \"user\", \"content\": \"<|image_5|>\\n<|image_6|>\\n<|image_7|>\\n<|image_8|>\\nAnalyze this sequence of frames where the red spot shows the user's eye gaze. Identify whether the user is performing a pick or place task and explain.\"},\n",
    "]\n",
    "\n",
    "#\"<|user|>\\n<|image_1|>\\n<|image_2|>\\n<|image_3|>\\n<|image_4|>\\n{Analyse the sequence of frames where the red spot shows the user's eye gaze. Always output only '0' if the task is pick or '1' if the task is place. Do not include any additional text or description.<|end|>\\n<|assistant|>\\n\"0\n",
    "\n",
    "\n",
    "for sample in data:\n",
    "    # Open images and create input messages\n",
    "    img_prompt = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/mcq/all_frames/Pick up jug from table_58929010438104.00\")\n",
    "    img = open_images_from_directory(\"/home/ttyh/hot3d/hot3d/dataset/Labelled/Videos/new_frames/gaze/\" + sample)\n",
    "    img_new = img_prompt + img\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    inputs = processor(prompt, img_new, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 1000, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    print(\"generate_ids: \", generate_ids)\n",
    "    \n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    generated_texts = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    # Check if the generated text matches the action class\n",
    "    action_class = str(df[df['Folder name'] == sample]['action_class'].iloc[0])\n",
    "    print(\"generated text: \", generated_texts)\n",
    "    if action_class in generated_texts:\n",
    "        print(\"correct\")\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        print(\"wrong\")\n",
    "    \n",
    "    # Update the DataFrame with the generated text\n",
    "    df.loc[df['Folder name'] == sample, 'Phi3.5(few)'] = int(float(generated_texts))\n",
    "    \n",
    "    # Delete the variables to free up memory\n",
    "    del img, prompt, inputs, generate_ids, generated_texts\n",
    "\n",
    "print(\"Accuracy: \", correct / (wrong + correct))\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(dataset_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
